{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3f38e76331204d648cbc267ff14c95cf139d2d4d"
   },
   "source": [
    "## Splitting data.\n",
    "\n",
    "First, I am going to split the data in train set and test set. Notice that the train set will be late split again for validation set. \n",
    "\n",
    "Right now, I will use 1000 images for testing, and the rest for training/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "f25812d88c6a404effae3813d0b0481c662abbb6"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "train_data = []  # This will later be split in validation too\n",
    "test_data = []\n",
    "for file in listdir(\"train/train\"):\n",
    "    some_number = random.randint(1,100)\n",
    "    label = \"1\" if \"dog\" in file else \"0\" \n",
    "    if len(test_data) >= 1000 or some_number < 85:\n",
    "        train_data.append([file, label])\n",
    "    else:\n",
    "        test_data.append([file, label])\n",
    "        \n",
    "train = pd.DataFrame(train_data, columns=[\"filename\", \"class\"])\n",
    "test = pd.DataFrame(test_data, columns = [\"filename\", \"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "f65554fb228a9b3c362f2d9de3cab1b142c00a6a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat.0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cat.1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cat.1000.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cat.10000.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat.10001.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        filename class\n",
       "0      cat.0.jpg     0\n",
       "1      cat.1.jpg     0\n",
       "2   cat.1000.jpg     0\n",
       "3  cat.10000.jpg     0\n",
       "4  cat.10001.jpg     0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "ec90f6ed68db7ee83820d52c293d72ca07ce845e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat.10.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cat.100.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cat.10009.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cat.10011.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat.10012.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        filename class\n",
       "0     cat.10.jpg     0\n",
       "1    cat.100.jpg     0\n",
       "2  cat.10009.jpg     0\n",
       "3  cat.10011.jpg     0\n",
       "4  cat.10012.jpg     0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "542a90fe1670f71e9117c42b52b77b4d2ee1653b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size 24000\n",
      "Test size 1000\n",
      "------------\n",
      "\tTrain has 11500 0\n",
      "\tTest has 1000 0\n",
      "------------\n",
      "\tTrain has 12500 1\n",
      "\tTest has 0 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Train size\", len(train))\n",
    "print(\"Test size\", len(test))\n",
    "\n",
    "for label in [\"0\", \"1\"]:\n",
    "    print(\"------------\")\n",
    "    print(\"\\tTrain has\", len(train[train[\"class\"]==label]), label)\n",
    "    print(\"\\tTest has\", len(test[test[\"class\"]==label]), label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e526b4dbe2241e0d54801c4fb453f395cb36c818"
   },
   "source": [
    "## The data is quite balanced, ~50% are dogs (class 1), ~50% are cats (class 0). As this is a binary problem, we can output a sigmoid as the output function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "4a2792c3438ca4a460c0fe3131336e83ab9bdfdc"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 64\n",
    "train_image_generator = ImageDataGenerator(rescale=1./255, \n",
    "                                           rotation_range=90, \n",
    "                                           horizontal_flip=True, \n",
    "                                           vertical_flip=True,\n",
    "                                           validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "41ec370eb467f20f43d396f10859534622610eba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19802 images belonging to 2 classes.\n",
      "Found 4198 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_image_generator.flow_from_dataframe(train, \"train/train\", seed=42,\n",
    "                                                    target_size=(IMG_SIZE[0], IMG_SIZE[1]),\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    class_mode=\"binary\",\n",
    "                                                    subset=\"training\",\n",
    "                                                    shuffle=True,      \n",
    "                                                    save_format=\"jpeg\")\n",
    "\n",
    "validation_generator = train_image_generator.flow_from_dataframe(train, \"train/train\", seed=42,\n",
    "                                                    target_size=(IMG_SIZE[0], IMG_SIZE[1]),\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    class_mode=\"binary\",\n",
    "                                                    subset=\"validation\",\n",
    "                                                    shuffle=False,                  \n",
    "                                                    save_format=\"jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "765f29c5b01ecdc61dd8178720e06fb3567d08a3"
   },
   "outputs": [],
   "source": [
    "from keras.applications import vgg16\n",
    "model = vgg16.VGG16(weights='imagenet', \n",
    "                    include_top=False, \n",
    "                    input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3), \n",
    "                    pooling=\"avg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6aae5d8c6c7e389331780d346730c7a7c5e55ae3"
   },
   "source": [
    "### Now, we are going to only train the last 5 layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "00de3a89c67179ad12142291ccbc165335562a2c"
   },
   "outputs": [],
   "source": [
    "for layer in model.layers[:-8]:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9d80ea21da4f5ccc8fe7e53d8c06adaaa7ad60ac"
   },
   "source": [
    "## Finally, we are going to add a Dense layer of 512 units and then the output layer (a sigmoid function) at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "72bec807f48188c3fa3eb7f325cded4cb6442fbb"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "# Although this part can be done also with the functional API, I found that for this simple models, this becomes more intuitive\n",
    "transfer_model_vgg16 = Sequential()\n",
    "\n",
    "for layer in model.layers:\n",
    "    transfer_model_vgg16.add(layer)\n",
    "transfer_model_vgg16.add(Dense(512, activation=\"relu\"))  # Very important to use relu as activation function, search for \"vanishing gradiends\" :)\n",
    "transfer_model_vgg16.add(Dense(1, activation=\"sigmoid\")) # Finally our activation layer! we use 2 outputs as we have either cats or dogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e793aeebac424218d44c2ccc1c3a2038f2186604"
   },
   "source": [
    "## Lets display our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "ee72277ccf19ed97b6b964a8345c38e091f49f40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 14,977,857\n",
      "Trainable params: 12,062,209\n",
      "Non-trainable params: 2,915,648\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transfer_model_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "7434e621ad7546d04ae5dbb1a7cb4415611cd67a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "309/309 [==============================] - 3937s 13s/step - loss: 0.3352 - acc: 0.8473 - val_loss: 0.1030 - val_acc: 0.9739\n",
      "Epoch 2/2\n",
      "309/309 [==============================] - 3818s 12s/step - loss: 0.1740 - acc: 0.9300 - val_loss: 0.2432 - val_acc: 0.9008\n"
     ]
    }
   ],
   "source": [
    "adam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.00001)\n",
    "transfer_model_vgg16.compile(adam,loss=\"binary_crossentropy\",metrics=[\"accuracy\"] )\n",
    "\n",
    "vgg16_model_history = transfer_model_vgg16.fit_generator(train_generator, \n",
    "                                             steps_per_epoch = train_generator.n // BATCH_SIZE,\n",
    "                                             validation_data = validation_generator,\n",
    "                                             validation_steps = validation_generator.n // BATCH_SIZE,\n",
    "                                            epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9d5745e1c0003714ee5c5027b2c51ce4ba4cc8e9"
   },
   "source": [
    "## Lets define a small function to plot our predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "ffec75d79e7f92d1a308291779f2102e811629f4"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "def plot_prediction(image_path, label):\n",
    "    display(Image(filename=image_path, width=IMG_SIZE[0], height=IMG_SIZE[1]))\n",
    "    prediction = \"dog\"\n",
    "    confidence = label\n",
    "    if label < 0.5:\n",
    "        prediction = \"cat\"\n",
    "        confidence = (1-label)\n",
    "    legend = \"The image %s above is a %s with a confidence of %.2f%% %f\" % (image_path, prediction, confidence*100, label)\n",
    "    print(legend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "202169372755992b3b1ac8766304f1b98b84d777"
   },
   "source": [
    "## And another function to efficiently yield batches of images and (optionally) labels to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_uuid": "ad6167ea73442630ecdff4668cbbf00cf554afd9"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage import io\n",
    "\n",
    "def build_batches(df, has_labels=True, limit=500, batch_size=BATCH_SIZE, produce=\"images\"):\n",
    "    \"\"\"\n",
    "    produce: Can be either \"images\" in which case an array of normalized images is returned or \n",
    "             \"paths\" in which case, a string with the full dir is returned\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    paths = []\n",
    "    i = 0\n",
    "    for _, row in df.iterrows():\n",
    "        if has_labels:\n",
    "            y.append(row[\"class\"])\n",
    "        raw_image_path = \"train/train/\" if has_labels else \"test/test/\"\n",
    "        raw_image_path += row[\"filename\"]\n",
    "        raw_image = io.imread(raw_image_path)\n",
    "        raw_image = cv2.resize(raw_image, (IMG_SIZE[0], IMG_SIZE[1]), interpolation=cv2.INTER_CUBIC)\n",
    "        X.append(raw_image)\n",
    "        paths.append(raw_image_path)\n",
    "        i += 1\n",
    "        if i == limit:\n",
    "            break\n",
    "        if i > 0 and i % batch_size == 0:\n",
    "            X = np.array(X)\n",
    "            y = np.array(y)\n",
    "            X = X / 255\n",
    "            \n",
    "            if produce == \"images\":\n",
    "                yield X, y\n",
    "            else:\n",
    "                yield paths, y\n",
    "            paths = []\n",
    "            X = []\n",
    "            y = []\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    X = X / 255\n",
    "    \n",
    "    if produce == \"images\":\n",
    "        yield X, y         \n",
    "    else:\n",
    "        yield paths, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "64801f354b7ac3fc287726c92c054641cc0f8e8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/15 [==============================] - 110s 7s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.25907485604286196, 0.9009999990463257]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = 1000\n",
    "transfer_model_vgg16.evaluate_generator(build_batches(test, limit=samples), steps=samples/BATCH_SIZE, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0c3ba32de8c63dbcb0329b8fe52edde90a136822"
   },
   "source": [
    "### Not a bad result, lets plot a couple of those images..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3ba0a06bc7fc5166dbc66798358a9730a775727b"
   },
   "outputs": [],
   "source": [
    "some_predictions = transfer_model_vgg16.predict_generator(build_batches(test, limit=12, batch_size=1), steps=12, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fcc6c5d001fe8a94d2765048354622b62f1bf4ee"
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for mini_batch_files, mini_batch_labels in build_batches(test, limit=samples, batch_size=1, produce=\"paths\"):\n",
    "    mini_batch_file = mini_batch_files[0]\n",
    "    mini_batch_label = mini_batch_labels[0]\n",
    "    predicted_label = some_predictions[idx][0]\n",
    "    idx += 1\n",
    "    #print(mini_batch_file, mini_batch_label, predicted_label)\n",
    "    plot_prediction(mini_batch_file, predicted_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0f1c702b8b8261ab8b3b8282e0561121d00d21bf"
   },
   "source": [
    "### Now, it would be interesting to plot images that are NOT correctly predicted... lets do that too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "51e05c72bde4e985d1d5746a43596d5a7881ab4f"
   },
   "outputs": [],
   "source": [
    "samples = 1000\n",
    "some_predictions = transfer_model_vgg16.predict_generator(build_batches(test, limit=samples, batch_size=1), steps=samples, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "378ff3639ceb417f8da0788d7ccc1ccb91a8606a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"Total predictions\", some_predictions.shape)\n",
    "idx = 0\n",
    "errors = 0\n",
    "for mini_batch_files, mini_batch_labels in build_batches(test, limit=samples, batch_size=1, produce=\"paths\"):\n",
    "    mini_batch_file = mini_batch_files[0]\n",
    "    mini_batch_label = mini_batch_labels[0]\n",
    "    predicted_label = some_predictions[idx][0]\n",
    "    if abs(float(mini_batch_label) - float(predicted_label)) > 0.5:\n",
    "        errors += 1\n",
    "        if errors < 10:\n",
    "            plot_prediction(mini_batch_file, predicted_label)\n",
    "    idx += 1\n",
    "print(\"Total errors...\", errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_uuid": "f87bd9d9d828dc53d8481a5696c778298d5606f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.jpg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.jpg</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000.jpg</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000.jpg</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    filename     id\n",
       "0      1.jpg      1\n",
       "1     10.jpg     10\n",
       "2    100.jpg    100\n",
       "3   1000.jpg   1000\n",
       "4  10000.jpg  10000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_limit = 12500\n",
    "i = 0\n",
    "output_df = []\n",
    "for file in listdir(\"test/test/\"):    \n",
    "    output_df.append([file, file.split(\".\")[0]])\n",
    "    i += 1\n",
    "    if i == my_limit:\n",
    "        break\n",
    "output = pd.DataFrame(output_df, columns=[\"filename\", \"id\"])\n",
    "print(len(output))\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1d2a6b49ce2bb2ca1c9d7fd54780f87388f185d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 28/195 [===>..........................] - ETA: 19:44"
     ]
    }
   ],
   "source": [
    "results = transfer_model_vgg16.predict_generator(build_batches(output, limit=-1, has_labels=False, batch_size=64), steps=12500/64, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "baa5db0fb27d69634e7f8a8486ba135ca231708b"
   },
   "outputs": [],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a2d7183e441b8c3d7c0a6ce710107f277af1de1e"
   },
   "outputs": [],
   "source": [
    "output[\"label\"] = results\n",
    "\n",
    "output.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ff5dd5dce9cdfb854a539d2f3c063c0f15b3afcf"
   },
   "source": [
    "## Lets plot a couple of predictions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "30b477f22327462dfc8795e8e560b27e58b610a9"
   },
   "outputs": [],
   "source": [
    "stop = 10\n",
    "for idx, row in output.iterrows():\n",
    "    path = \"test/test/\" + row[\"id\"] + \".jpg\"\n",
    "    plot_prediction(path, row[\"label\"])\n",
    "    stop -= 1\n",
    "    if stop == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "09e600d13c1341a3db00f20fb142b74ae5c5c6b6"
   },
   "source": [
    "## And finally prepare the output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "24c6183f4a32f66c55e7e51f1ec0a29fed31a490"
   },
   "outputs": [],
   "source": [
    "del output[\"filename\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "80d64a408889a8443f377c91ab4994a4188de049"
   },
   "outputs": [],
   "source": [
    "output.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7c268c3aa0f2201cc58c0f27628f4caaa78a390c"
   },
   "outputs": [],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2b99fd902bc3bad486e509862439b2686a23fcf9"
   },
   "outputs": [],
   "source": [
    "output.to_csv(\"submission_file.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
